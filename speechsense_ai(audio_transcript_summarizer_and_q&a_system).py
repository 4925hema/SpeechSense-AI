# -*- coding: utf-8 -*-
"""SpeechSense AI(Audio Transcript Summarizer and Q&A System).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eZdamlbffJB2jotdv4NDLoiMqpbW8JEw
"""

!pip install speechrecognition

import speech_recognition as sr

model = sr.Recognizer()

!pip install pydub

mp3_file =r'/content/Machine Learning Explained in 100 Seconds.mp3'
from pydub import AudioSegment
from pydub.playback import play
audio = AudioSegment.from_mp3(mp3_file)
audio.export('temp.wav', format='wav')

audio_file =r'/content/temp.wav'
with sr.AudioFile(audio_file) as source:
  #reco.adjust_for_ambient_noise(source)
  audio_data = model.record(source)
  text = model.recognize_google(audio_data)
text

text

!pip install pytesseract

from PIL import Image
import pytesseract
import matplotlib.pyplot as plt

!pip install gtts

from gtts import gTTS

!pip install transformers

from transformers import pipeline

summerize = pipeline("summarization")

text = input('')

result = summerize(text)

result

from transformers import pipeline

# Load a pre-trained question-answering pipeline from Hugging Face
qa_pipeline = pipeline("question-answering")

# Function to ask questions and get answers based on the provided context
def ask_user_questions():
    # Default context
    context = '''Machine learning teach a computer how to perform a task without explicitly programming it to perform set task instead feed data into an algorithm to gradually improve outcomes . The term was coined in 1959 by Arthur Samuel at IBM who is developing artificial intelligence that could play checkers half a century later . Predictive models are embedded in many of the products we use every day'''

   # print("Welcome to the interactive story! Ask me any question about Luca's adventure.")

    # Loop to continuously take user questions
    while True:
        # Ask the user to input a question
        user_question = input("Ask a question (or type 'exit' to quit): ").lower()

        # Exit condition
        if user_question == 'exit':
            print("Goodbye!")
            break

        # Use the pipeline to get the answer from the model
        result = qa_pipeline(question=user_question, context=context)

        # Print the answer
        print("Answer:", result['answer'])

        # Ask if the user wants to ask another question
        continue_choice = input("Do you want to ask another question? (yes/no): ").lower()
        if continue_choice != 'yes':
          print("Goodbye!")
          # Corrected indentation for the break statement
          break  # Exit if the user does not want to continue

# Start the question-answering loop
ask_user_questions()

from transformers import pipeline

text_input =input('enter some text')

analyzer = pipeline("sentiment-analysis")

res = analyzer(text_input)